sequential observations
    learner
        targets use longer input length then trained loss
        episode boundaries are crossed for loss and actor
additional capabilities
    gymnasium play and show
    crypto environment
        add profit state to each kline
evaluation
    targets mean and std
optimizations
    correct target scaling
    correct seeding
    initialize optimizer only for learner, copy only parameters
    ram usage
    float32
    jax everything
terminal messages
    Segmentation fault
    probabilities containing NaN
next commit
    message: added better reward scaling & target metrics